{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import fitz\n",
    "import glob\n",
    "import nltk\n",
    "import glob\n",
    "import cv2\n",
    "import spacy\n",
    "import spacy.cli\n",
    "from spacy.language import Language\n",
    "from spacy_langdetect import LanguageDetector\n",
    "import easyocr\n",
    "import pytesseract\n",
    "import numpy as np\n",
    "import textseg as ts\n",
    "from spacy import displacy\n",
    "from PyPDF2 import PdfFileReader\n",
    "from pdf2image import convert_from_path\n",
    "\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('stopwords')\n",
    "# spacy.cli.download(\"en_core_web_lg\")\n",
    "\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe' #tesseract.exe location in your computer"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# SKILLS EXTRACTION\n",
    "# Add skills database from a file\n",
    "def add_skills_data(filePath):\n",
    "    skills = []\n",
    "\n",
    "    for data in open(filePath, 'r', encoding='UTF-8'):\n",
    "        skills.append(data.strip())\n",
    "\n",
    "    return skills\n",
    "\n",
    "# Get the text from a file\n",
    "def extract_text(filePath, remove_line=False):\n",
    "    with fitz.open(filePath) as doc:\n",
    "        text = \"\"\n",
    "        for page in doc:\n",
    "            text += page.get_text()\n",
    "\n",
    "        if remove_line:\n",
    "            text = text = re.sub('\\s', \" \", text)\n",
    "\n",
    "    return text\n",
    "\n",
    "# Extract the skills based on the skill database\n",
    "def extract_skills(input_text, skills_data):\n",
    "    stop_word = set(nltk.corpus.stopwords.words('english'))\n",
    "    word_tokens = nltk.tokenize.word_tokenize(input_text)\n",
    "\n",
    "    filtered_tokens = [w for w in word_tokens if w not in stop_word]\n",
    "    filtered_tokens = [w for w in word_tokens if w.isalpha()]\n",
    "    bigrams_trigrams = list(map(' '.join, nltk.everygrams(filtered_tokens, 2, 3)))\n",
    "\n",
    "    skills = set()\n",
    "\n",
    "    for token in filtered_tokens:\n",
    "        if token in skills_data:\n",
    "            skills.add(token)\n",
    "\n",
    "    for ngram in bigrams_trigrams:\n",
    "        if ngram in skills_data:\n",
    "            skills.add(ngram)\n",
    "\n",
    "    return skills\n",
    "\n",
    "# Extract skills from a single file\n",
    "def extract_single_skills(filePath, skills):\n",
    "    text = extract_text(filePath)\n",
    "\n",
    "    return  extract_skills(text, skills)\n",
    "\n",
    "# Extract skills from a folder full of pdf\n",
    "def extract_batch_skill(filePath, skills):\n",
    "    data = {\"File\": [], 'Skill': []}\n",
    "\n",
    "    for file in glob.glob('{}*.pdf'.format(filePath)):\n",
    "        text = extract_text(file, True)\n",
    "        data['File'].append(file)\n",
    "        data['Skill'].append(extract_skills(text, skills))\n",
    "\n",
    "    return data\n",
    "\n",
    "# DOCUMENT SEGMENTATION\n",
    "# Converting from pdf to image for segmentation\n",
    "def convert_pdf_to_image(filepath,img_path_to_save):\n",
    "    try:\n",
    "        fileName = filepath.split(\"/\")[-1].replace(\".pdf\",\"\")\n",
    "        pages = convert_from_path(filepath, 350)\n",
    "        i = 1\n",
    "        for page in pages:\n",
    "            image_name = img_path_to_save+fileName+\"Page_\" + str(i) + \".png\"\n",
    "            page.save(image_name, \"JPEG\")\n",
    "            i = i+1\n",
    "        return {\"status\":200,\"response\":\"PDF Converted to image sucessfully\",\"fileName\":fileName}\n",
    "    except Exception as e:\n",
    "        return {\"status\":400,\"response\":str(e)}\n",
    "\n",
    "# Extract text from a png\n",
    "def text_from_tesseract(output_img):\n",
    "    text = str(((pytesseract.image_to_string(output_img))))\n",
    "    return text\n",
    "\n",
    "def text_from_easyocr(img, reader):\n",
    "    all_text = \"\"\n",
    "    result = reader.readtext(img)\n",
    "\n",
    "    for (bbox, text, prob) in result:\n",
    "        all_text += text + \" \"\n",
    "\n",
    "    return all_text\n",
    "\n",
    "\n",
    "# Segment and then extract the data from a resume\n",
    "def segment_extract_data(data,  path_to_write, reader, singleFile=True):\n",
    "    documents = [] # file path nya untuk pdf\n",
    "\n",
    "    if singleFile:\n",
    "        documents.append(data)\n",
    "    else:\n",
    "        documents = data\n",
    "\n",
    "    final_name_list=[] # nama file\n",
    "    final_text_opencv=[] # text dengan segmen\n",
    "    # final_text_tessaract=[]\n",
    "    final_text_easyocr=[] # semua text tanpa segmen\n",
    "    for i in documents:\n",
    "        pdf = PdfFileReader(open(i,'rb'))\n",
    "        fname = i.split('/')[-1]\n",
    "\n",
    "        # if pdf.getNumPages() > 3:\n",
    "        #     print('Pages to many : {}!, Skipping...'.format(pdf.getNumPages()))\n",
    "        #     continue\n",
    "\n",
    "        images = convert_from_path(i)\n",
    "        resumes_img=[]\n",
    "        for j in range(len(images)):\n",
    "            # Save pages as images in the pdf\n",
    "            images[j].save(path_to_write+fname.split('.')[0]+'_'+ str(j) +'.jpg', 'JPEG')\n",
    "            resumes_img.append(path_to_write+fname.split('.')[0]+'_'+ str(j) +'.jpg')\n",
    "        name_list = fname.split('.')[0]+'_' +'.jpg'\n",
    "        text_opencv=[]\n",
    "        # text_tessaract=[]\n",
    "        text_easyocr=[]\n",
    "        for i in resumes_img:\n",
    "            frame=cv2.imread(i)\n",
    "            os.remove(i)\n",
    "            img = i.split(\"/\")[2]\n",
    "\n",
    "            output_img,label,dilate, c_dict,df1, split_img=ts.get_text_seg(frame, img)\n",
    "            cv2.imwrite(path_to_write+img.split('.')[0]+\".png\",output_img)\n",
    "            for i in range(len(split_img)):\n",
    "                cv2.imwrite(path_to_write+img.split('.')[0]+str(i)+\".png\", split_img[i])\n",
    "\n",
    "            text_opencv.append(c_dict)\n",
    "            # text_tessaract+=text_from_tesseract(output_img)\n",
    "            # tesseract_str = ''.join(text_tessaract)\n",
    "            text_easyocr+=text_from_easyocr(output_img, reader)\n",
    "            easyocr_str = ''.join(text_easyocr)\n",
    "\n",
    "        final_name_list.append(name_list)\n",
    "        final_text_opencv.append(text_opencv)\n",
    "        # final_text_tessaract.append(tesseract_str)\n",
    "        final_text_easyocr.append(easyocr_str)\n",
    "\n",
    "    return final_text_opencv, final_name_list, final_text_easyocr\n",
    "\n",
    "# EXPERIENCE EXTRACTION\n",
    "# Extract exp from a text\n",
    "def extract_exp(textList, nlp):\n",
    "    exp = []\n",
    "\n",
    "    for i in range(len(textList)):\n",
    "        for j in range(len(textList[i])):\n",
    "            for _, text in textList[i][j].items():\n",
    "                text = re.sub(r'[^\\w\\s]+', \"\", text)\n",
    "                text = re.sub(r'[\\s]{2,}', \" \", text)\n",
    "                text = re.sub(r'https\\w+', \"\", text)\n",
    "                doc = nlp(text)\n",
    "                if doc.cats['experience'] > 0.70:\n",
    "                    exp.append(text)\n",
    "\n",
    "    return exp\n",
    "\n",
    "# Do all the above with just 1 function\n",
    "def extract_data(filePath, skills, nlp, temp_path, reader):\n",
    "    file_data = {'File': \"\", 'Skills':\"\", \"Exp\":\"\"}\n",
    "\n",
    "    textList, fileName, fullText = segment_extract_data(filePath, temp_path, reader)\n",
    "    file_data['File'] = fileName[0]\n",
    "    file_data['Skills'] = extract_skills((fullText[0]), skills_data=skills)\n",
    "    file_data['Exp'] = extract_exp(textList, nlp)\n",
    "\n",
    "    return file_data\n",
    "\n",
    "def batch_extract_data(filePath, skills, nlp, temp_path):\n",
    "    file_data = {'File': [], 'Skills': [], \"Exp\": []}\n",
    "\n",
    "    for file in os.listdir(filePath):\n",
    "        data = extract_data('{}/{}'.format(filePath, file), skills, nlp, temp_path)\n",
    "        file_data['File'].append(data['File'])\n",
    "        file_data['Skills'].append(data['Skills'])\n",
    "        file_data['Exp'].append(data['Exp'])\n",
    "\n",
    "    return file_data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CUDA not available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CPU device\n",
      "Using CPU device\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'File': 'Muhammad Herliroza - CV - Muhammad Herliroza Ananda_.jpg',\n 'Skills': {'Government',\n  'Hospitality Industry',\n  'Management System',\n  'Organization',\n  'Outsourcing',\n  'Project',\n  'Public',\n  'Public Administration',\n  'Screening',\n  'Vendor Management'},\n 'Exp': ['e Creating company profile promoting and finding companies that need labor services such as security driver cleaning serviceoffice boygirl admin receptionist and secretaries e Presenting to clients about the services offered by Karya Deinda Sejahtera e Ensuring the company provides the best service and clients are happy with the services of\\nthe company so that they can use our companys services again e Saving company administration such as company profile legality data contract BAST tax\\nsettlement financial statements for presenting to clients JULY 2020 DECEMBER 2020\\nBARISTA STARBUCKS INDONESIA\\nTask ',\n  'Acts with integrity honesty and knowledge that promote the culture values and mission\\nof Starbucks Maintains a calm demeanor during periods of high volume or unusual events to keep store\\noperating to standard and to set a positive example for the team Anticipates costumer and store needs by constantly evaluating environment and\\ncostumers for cues Communicates information to manager so that the team can respond as necessary to\\ncreate the third place environment during each shift ',\n  'APRIL 2019 DECEMBER 2019 COFOUNDER TACIT EVENT ORGANIZER Tacit is an event organizer engaged in music that aims to accommodate local talents in\\nSurakarta to show their talents by showcasing their music Task Achievement Leading supervise and be responsible for all series of events that held by Tacit Creating event concept budgeting and selling event tickets Approach the appropriate venue and sponsors to collaborate in the event Succeeded reach more than 3000 audiences in the entire series of events and gained Rp\\n10000000 profit in every main event Succeeded to collaborate with a wellknown venue in Surakarta and received sponsorship\\nfrom wellknown products such as the PT Djarum PT HM Sampoerna and Bentoel Group\\nSucceeded contracted by the venue to run their weekly event for 3 months ',\n  'MARCH 2019 MAY 2020 COFOUNDER MELANGKAH LEBIH DEKAT Melangkah Lebih Dekat is a social community that concerns about kids education that has\\nfinancial issues and health problems Task Achievement\\ne Create project planning lead the team to execute the project control the social media coordinating operations\\ne Managed 3 social project education for kids and during the covid19 pandemic made\\ndonations to distribute food to people living on the streets in Surakarta ']}"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adding skills database\n",
    "skills = add_skills_data('list_of_skills.txt')\n",
    "skills[0] = '.NET' # First skills is not UTF-8 so we need to replace it\n",
    "\n",
    "# Segmentation need a temp folder for storing image that will be scanned for extraction the text\n",
    "temp_path = ('./segmentation/')\n",
    "\n",
    "# Load the machine learning model for exp classification\n",
    "nlp = spacy.load('model_exp')\n",
    "\n",
    "reader = easyocr.Reader(['en'])\n",
    "\n",
    "# Get the filename, skills, exp\n",
    "data = extract_data('./Lampirkan CV terupdate Anda (File responses)/Muhammad Herliroza - CV - Muhammad Herliroza Ananda.pdf', skills, nlp, temp_path, reader)\n",
    "\n",
    "data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling [autocast_mode.py:162]\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\"> BEASISWA UNGGULAN KEMENTERIAN PENDIDIKAN DAN KEBUDAYAAN BEST \n<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n    BUSINESS PLAN\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Job</span>\n</mark>\n IN MARKETING COMMUNICATION CLASS SELECTED AS ONE THE 25 BEST ESSAY WRITERS THE BEST MARKETING SCORE PRESENTATION IN CERTIFICATION AMA 2020 S K I L L putrisoegiharto yahoo com C O N T A C T M E A T P R O F I L E PUTRI AYU MERDEKAWATI HS 087808111958 E D U C A T I O N BACHELOR OF MANAGEMENT Universitas Kristen Maranatha Faculty of Economics Bachelor Program in Management Graduated in September 2020 GPA 3 63 Cum Laude C E R T I F I C A T I O N \n<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n    MARKETING MANAGEMENT\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Job</span>\n</mark>\n Competency test certificated \n<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n    Marketing Management\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Job</span>\n</mark>\n By Asosiasi Manajemen Indonesia AMA 2020 I am a 23 years old fresh graduate from Management Major with the focus on \n<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n    Marketing\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Job</span>\n</mark>\n I always want to develop myself and learn a lot for increase my skill especially in \n<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n    marketing\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Job</span>\n</mark>\n field I am a good communicative and persuasive person that have experience in branding selling products communicating creative contents Communication Creativity Coordinating Leadership Team work Management skill Microsoft Office Language English Intermediate Language Japanese class reguler level 2 A C H I E V E M E N T Get a Scholarship Beasiswa Unggulan Masyarakat Berprestasi Paper Presentation Became a speaker as a Beasiswa Unggulan Kementerian Pendidikan dan Kebudayaan Awardee and share international campus organization experience Created creative content implemented \n<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n    marketing\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Job</span>\n</mark>\n programs estabilished by the company learned the programming of data input applications for inventoris and tax invoices Selected as one the 25 best essay writers with the theme Opportunities Challenges for Bandung City Development through the Bandung Sister Cities Program W O R K E X P E R I E N C E PT DANAMARTHA SEJAHTERA UTAMA \n<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n    Marketing Intern\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Job</span>\n</mark>\n 2019 2020 INTERNATIONAL OFFICE E X P E R I E N C E \n<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n    Head of Coordinator\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Job</span>\n</mark>\n of Volunteer International Office 2018 2020 Comparative study in Universiti Kebangsaan Malaysia and Universiti of Malaya Created activity program and events with different themes that involve interaction with students from other countries and student exchange FIND INTERESTING IN A RELATIONSHIP ECONOMICS PROGRAM SEVERAL SEMINARS RELATED TO MARKETING BUSINESS ECONOMY HOKUSEI GAKUEN UNIVERSITY SUMMER PROGRAM DISCOVER MALAYSIA COMPARATIVE STUDY Speaker 2019 Participants 2019 Committee 2019 BHINEKKA TRIP Tour Guide Trip Planner 2019 Putri Ayu Merdekawati HS Jl Dahlia Utama no 9 Taman Lembah Hijau Lippo Cikarang PT TALENTA WIRAMA BERKAT Assisten Team 2021 Assisten Team for Project Fruit Tea World Festival </div></span>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import fitz\n",
    "import spacy\n",
    "import spacy.displacy\n",
    "\n",
    "nlp = spacy.load('model_job')\n",
    "\n",
    "def extract_text(filePath, remove_line=False):\n",
    "    with fitz.open(filePath) as doc:\n",
    "        finaltext = \"\"\n",
    "        for page in doc:\n",
    "            text = page.get_text()\n",
    "            text = text.replace(\"\\n\",\" \")\n",
    "            text = text.replace(\"[^a-zA-Z0-9]\", \" \");\n",
    "            text = re.sub('\\W+',' ', text)\n",
    "            text = re.sub('[^A-Za-z0-9]',' ', text)\n",
    "            finaltext += text\n",
    "\n",
    "        if remove_line:\n",
    "            finaltext = text = re.sub('\\s', \" \", text)\n",
    "\n",
    "    return finaltext\n",
    "\n",
    "text = extract_text('./Lampirkan CV terupdate Anda (File responses)/CV_PUTRI AYU MERDEKAWATI HS - Putri Ayu Merdekawati HS.pdf')\n",
    "\n",
    "doc = nlp(text)\n",
    "\n",
    "displacy.render(doc, style='ent')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "data": {
      "text/plain": "{'business plan',\n 'head of coordinator',\n 'marketing',\n 'marketing intern',\n 'marketing management'}"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "job = set()\n",
    "\n",
    "for a in doc.ents:\n",
    "    job.add(str(a).lower())\n",
    "\n",
    "job"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}